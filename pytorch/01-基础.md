# 概述

官网

[PyTorch](https://pytorch.org/)



github

[pytorch/pytorch: Tensors and Dynamic neural networks in Python with strong GPU acceleration (github.com)](https://github.com/pytorch/pytorch)



PyTorch是一个开源的Python机器学习库，基于Torch，用于自然语言处理等应用程序。它既可以看作加入了GPU支持的numpy，同时也可以看成一个拥有自动求导功能的强大的深度神经网络。除了Facebook外，它已经被Twitter、CMU和Salesforce等机构采用。

# 目录介绍

```shell
│── android 用于在 android平台上运行PyTorch模型的工具和示例
│── aten	张量计算的库，用于在CPU和GPU上进行张量操作。 
│── binaries 构建和测试PyTorch的脚本和配置文件
│── c10		基础设施和公共组件（错误处理、日志记录、配置管理），如张量数据结构（表示和操作多维数据）、设备抽象（表示计算设备，如CPU、GPU）、内核调度（用于在不同设备和数据类型上调度和执行操作）
│── caffe2	Fb开发的深度学习框架，PyTorch和Caff2合并，共享了底层的计算库 │── cmake	  构建PyTorch的cmake脚本
│── functorch 是PyTorch的子项目，目标是使PyTorch支持函数式编程
│── ios		用于在ios平台上运行PyTorch模型的工具和示例
│── modules  特定功能的可选模块，用户可以根据需要是否安装
│── mypy_plugins 类型检查插件
│── scripts		常见的任务脚本，构建、测试、ci/cd、生成文档、管理依赖、处理数据
│── third_party	外部项目依赖库，如数据运算、并行计算、网络通信
│── tools		开发和维护PyTorch的工具
│── torch		核心源代码，c++ api；张量操作、神经网络模块、自动微分；PyTorch api； cpu、cuda、xla操作等;数据加载的data、用于优化的optim、分布式计算的distributed
│── torchgen	生成PyTorch模型的工具，模型生成器
```

torch

```shell
│── __init__.py		PyTorch的主要入口点，它导入了所有的子模块，并定义了一些全局变量和函数
│── _c				包含了PyTorch的c++实现的Pythor绑定，这些绑定使得Python代码可以调用c++实现的函数。
│── autograd		包含了PyTorch的自动微分系统的实现，自动计算梯度
│── nn				神经网络模块，提供了一些构建神经网络的类和函数
│── optim			优化器，用于更新神经网络的参数
│── utils			工具函数和类，如数据加载和处理的工具
│── jit				JIT编译器的实现，可以将PyTorch代码编译成机器代码，提高运行效率
│── onnx			对ONNX格式的支持，onnx是一种用于表示深度学习模型的开放格式
│── distributed		PyTorch的分布式计算的实现
│── cuda			PyTorch对CUDA支持，使得PyTorch可以在NVIDIA的GPU上运行

│── amp				自动混合精度，单精度（float32）和半精度（float16）之间切换
│── ao				application Optimization，优化应用程序性能的工具
│── backends		后端的支持，指的是执行计算的硬件或软件，如CPU、GPU或者特定的深度学习加速器
│── compiler		编译器相关，将PyTorch的模型或者操作转换为更低级的表示，如将PyTorch的模型转为TorchScript，或者将PyTorch的操作转换为LLVM IR。以提高效率，和在更多硬件的支持
│── contrib			存放社区贡献的工具和模块
│── cpu				cpu后端，实现了所有在CPU上的操作，张量的基本操作（加法、乘法等），线性代数操作（如矩阵乘法、求逆等），卷积操作等
│── csrc			包含了PyTorch的C++源码和Python绑定的实现
│── export			将模型导出为 ONNX 格式
│── fft				提供了快速傅里叶变换（Fast Fourier Transform，FFT）的功能,傅里叶变换它可以用来将信号从时域转换到频域，或者从频域转换到时域。这种变换对于信号处理、图像处理、语音识别等领域非常重要。
│── func			框架进行各种计算操作
│── futures			并发编程的模型，它表示一个可能还没完成的计算，你可以在一个future上注册回调函数，当这个future完成时，这些回调函数会被调用。
│── fx				用于捕获和转换 PyTorch 程序（可以理解为神经网络结构）的纯 Python 系统,三个组件：符号追踪器（symbolic tracer），中间表示（intermediate representation），以及 python 代码生成（python code generation）,主要是为了弥补动态计算图在模型部署调优阶段的不足，而静态计算图更适合这一阶段
│── legacy			orch/legacy 目录主要是为了保留和提供一些过时的 legacy 代码，以供特定场景或模型使用。在使用这些代码时需要谨慎评估其适用性和风险。
│── lib				库文件,实现一些特定功能和操作的动态链接库（.dll）或共享对象（.so）文件,如 libtorch_cpu.so（针对 CPU 设备的库文件）和 libtorch_cuda.so（针对 GPU 设备的库文件）
│── linalg			对线性代数的支持, 开发者可以更方便地处理和操作张量，例如计算矩阵的秩、逆、特征值等，以及进行向量和矩阵的运算等。
│── masked			对张量进行掩码操作，即根据给定的掩码（mask）将张量中的一些值掩盖掉。这种操作在Transformer和BERT等深度学习模型中都有应用。torch/masked 模块中的函数原型为 tensor.masked_fill(mask, value)，其中 mask 中为1的部分会被替换为 value（通常为一个极大或极小值），而 mask 中为0的部分会保持原值不变。这种掩码操作可以用于对数据进行筛选、替换或者填充等操作，从而实现对数据集的预处理、特征提取等任务。
│── monitor			模型训练过程的监控和调试的工具,如日志记录器（Logger）、摘要工具（Profiler）和指标计算器（Metric）等
│── mps				基于苹果的 Metal Performance Shaders (MPS) 作为后端，实现了 GPU 加速训练。
│── multiprocessing  多进程编程的模块,torch.multiprocessing 模块基于 Python 的内置 multiprocessing 库，并扩展了其功能以支持 PyTorch 张量操作和 nn.Module 实例。使用 torch.multiprocessing，您可以在多个进程中创建 PyTorch 张量和模型，并利用多核处理器同时进行计算。
│── nested			张量（nested tensors）的数据结构
│── package			将PyTorch模型以独立、稳定的格式打包的新方法。打包一个模型通常会包括模型的数据（如参数、缓冲区）和它的代码（模型架构）
│── profiler		于性能分析的模块，它可以帮助开发者深入分析PyTorch模型的性能瓶颈和效率问题。通过记录和分析模型在训练和推理过程中的各种操作和事件，开发者可以发现模型性能的瓶颈，优化模型的运行速度，提高模型的效率。
│── quantization	提供了用于量化深度神经网络的方法
│── signal			提供了信号处理的功能，包括滤波器、频谱分析等。这个模块可以用来分析和处理信号数据，例如音频、图像、STFT（短时傅里叶变换）等。
│── sparse			专门处理稀疏张量的模块。对于一个存在大量空值的稀疏张量，顺序存储的效率显得较为低下。因此，torch.sparse模块采用了有效的存储方式，通过定义稀疏张量的处理方式，仅存储有意义的值（被称为specified elements），而忽略无意义的值（空值，通常为0，但也可以是其他值）。这种方式能够有效地存储和处理大多数元素为零的张量。
│── special			特殊函数的实现，如Bessel函数、Gamma函数、误差函数、概率分布函数（正态分布、泊松分布函数）、贝塞尔函数、几何函数、拉曼光谱、数学函数（如平方根、对数）
```



# 核心概念

GitHub Copilot: PyTorch 的核心概念主要包括以下几个：

1. **张量（Tensor）**：PyTorch 中的基本数据结构，可以在 CPU 或 GPU 上进行操作。它类似于 NumPy 的 ndarray，但还可以在 GPU 上进行计算，还可以计算其自动梯度。

2. **计算图（Computational Graph）**：PyTorch 使用动态计算图，这意味着图在每次迭代时都会重新构建。这使得模型更加灵活，可以在运行时改变图的结构。

3. **自动微分（Autograd）**：PyTorch 中的自动微分引擎，用于计算神经网络的梯度。通过 Autograd，你可以自动计算任何计算图的梯度。

4. **神经网络（Neural Networks）**：PyTorch 提供了 `torch.nn` 包，用于构建神经网络。它提供了各种层和损失函数，你可以使用它们来构建自己的神经网络。

5. **优化器（Optimizer）**：PyTorch 提供了 `torch.optim` 包，用于优化神经网络的参数。它包含了各种优化算法，如 SGD、Adam 和 RMSProp。

6. **数据加载（Data Loading）**：PyTorch 提供了 `torch.utils.data` 包，用于加载和预处理数据。它提供了 `Dataset` 和 `DataLoader` 类，可以用于构建自定义的数据加载和预处理管道。

7. **模型保存和加载（Model Saving and Loading）**：PyTorch 提供了简单的 API 来保存和加载模型。你可以保存整个模型，也可以只保存模型的参数。

以上就是 PyTorch 的一些核心概念。理解这些概念对于使用 PyTorch 构建和训练神经网络是非常重要的。